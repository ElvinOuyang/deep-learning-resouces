{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oycy\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\oycy\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\oycy\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\oycy\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\oycy\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\oycy\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\oycy\\.conda\\envs\\tf35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\Users\\oycy\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\oycy\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\oycy\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\oycy\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\oycy\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\oycy\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=1):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf implementation of RNN (single cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation Graph Construct Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample code runs rnn that goes 2 time steps, taking input vector of size 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weight for input X at current time t\n",
    "Wx = tf.Variable(tf.random_normal(shape=[n_input, n_neurons], dtype=tf.float32))\n",
    "# initialize weight for input X at previous time t-1. The input shape of this should be\n",
    "# output length of the neuron at t-1, which is n_neurons\n",
    "Wy = tf.Variable(tf.random_normal(shape=[n_neurons, n_neurons], dtype=tf.float32))\n",
    "b = tf.Variable(tf.zeros([1, n_neurons], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y0 = tf.tanh(tf.matmul(X0, Wx) + b)\n",
    "Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)\n",
    "# Y2 = tf.tanh(tf.matmul(Y1, Wy) + tf.matmul(X2, Wx) + b)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Execution Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create some sythetic data to showcase the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Minibatch        instance_0, instance_1, instance_2, instance_3\n",
    "X0_batch = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 0, 1]]) # t=1\n",
    "X1_batch = np.array([[9, 8, 7], [0, 0, 0], [6, 5, 4], [3, 2, 1]]) # t=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    y0_val, y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.91210926 -0.97909343 -0.9963769  -0.80419695  0.81554604]\n",
      " [-0.9984175  -0.99501723 -0.9999901  -0.999553    0.878944  ]\n",
      " [-0.9999729  -0.9988196  -1.         -0.99999917  0.92149407]\n",
      " [ 0.9867836   1.          1.         -0.5567072  -0.9989797 ]]\n"
     ]
    }
   ],
   "source": [
    "print(y0_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.9999856   0.8339144  -0.9999801  -0.99999195 -0.97266006]\n",
      " [-0.92764604  0.8301138   0.03124466  0.95625156 -0.9378031 ]\n",
      " [-0.999539    0.97095305 -0.99141777 -0.9961223  -0.9843221 ]\n",
      " [-0.5459391  -0.39203942  0.943575   -0.9999922   0.93447596]]\n"
     ]
    }
   ],
   "source": [
    "print(y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few methods to use \"static\" ways to unwrap a RNN layer, but instead a `dynamic_rnn` is going to be way easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "# define an input with a known n_steps and n_inputs\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "# seq_length should be each instance's length, when input\n",
    "# instance is of various lengths\n",
    "seq_length = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic cell is like a factory that will create the rnn neurons\n",
    "basic_cell = tf.keras.layers.SimpleRNNCell(units=n_neurons)\n",
    "# both outputs (Y1) and states (Y0) needs to be stored\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32, sequence_length=seq_length)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with a various length list of sequence (padded to be just 2 steps long)\n",
    "X_batch = np.array([\n",
    "    # step 0 step 1\n",
    "    [[ 0, 1, 2], [9, 8, 7]], # instance 0\n",
    "    [[ 3, 4, 5], [0, 0, 0]], # instance 1 (padded with a zero vector)\n",
    "    [[ 6, 7, 8], [6, 5, 4]], # instance 2\n",
    "    [[ 9, 0, 1], [3, 2, 1]], # instance 3\n",
    "])\n",
    "seq_length_batch = np.array([ 2, 1, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs, states = sess.run(\n",
    "        [outputs, states], feed_dict={X:X_batch, seq_length:seq_length_batch}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.95115983 -0.9610069   0.94697636  0.9527325   0.06647953]\n",
      "  [ 1.         -0.9999789   0.99999994  1.         -0.61731684]]\n",
      "\n",
      " [[ 0.99999803 -0.99981755  0.99987227  0.99999624  0.11031032]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 1.         -0.99999917  0.9999998   1.          0.15371612]\n",
      "  [ 0.9999994  -0.99534667  0.9999252   0.99999213 -0.6344111 ]]\n",
      "\n",
      " [[ 0.9999957   0.9977971   0.3841205   0.99995565 -0.84551716]\n",
      "  [ 0.9876907   0.79720205  0.78417754  0.99387246 -0.23067977]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first (`batch_size`) and second (`n_steps`) dimensions keeps the same for the outputs tensor after the RNN layer. The third dimension is `n_neurons`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.9999789   0.99999994  1.         -0.61731684]\n",
      " [ 0.99999803 -0.99981755  0.99987227  0.99999624  0.11031032]\n",
      " [ 0.9999994  -0.99534667  0.9999252   0.99999213 -0.6344111 ]\n",
      " [ 0.9876907   0.79720205  0.78417754  0.99387246 -0.23067977]]\n"
     ]
    }
   ],
   "source": [
    "print(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `states` is the neuron outputs of the `last step` in the sequence; therefore, is has the size of `batch_size` by `n_neurons`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a RNN neural network with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "The 28 * 28 input data of MNIST can be processed as 28 steps of 28-element vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_neurons = 150\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the RNN layers\n",
    "with tf.name_scope('RNN'):\n",
    "    basic_cell = tf.keras.layers.SimpleRNNCell(units=n_neurons)\n",
    "    # dynamic_run here takes care of remembering the hidden states for \n",
    "    outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "\n",
    "logits = tf.layers.dense(states, n_outputs, name=\"FC\")\n",
    "\n",
    "with tf.name_scope('Loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "with tf.name_scope('training'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope('validation'):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 17:43:49.834811  1652 deprecation.py:323] From <ipython-input-27-296044d6dcb8>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0822 17:43:49.835774  1652 deprecation.py:323] From C:\\Users\\oycy\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0822 17:43:49.837770  1652 deprecation.py:323] From C:\\Users\\oycy\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 17:43:50.173022  1652 deprecation.py:323] From C:\\Users\\oycy\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0822 17:43:50.226744  1652 deprecation.py:323] From C:\\Users\\oycy\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/tmp/data/')\n",
    "X_test = mnist.test.images.reshape((-1, n_steps, n_inputs))\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Train accuracy: 0.94666666 Test accuracy: 0.9318\n",
      "Epoch:  1 Train accuracy: 0.96 Test accuracy: 0.9522\n",
      "Epoch:  2 Train accuracy: 0.98 Test accuracy: 0.9649\n",
      "Epoch:  3 Train accuracy: 0.99333334 Test accuracy: 0.9659\n",
      "Epoch:  4 Train accuracy: 0.99333334 Test accuracy: 0.9625\n",
      "Epoch:  5 Train accuracy: 0.97333336 Test accuracy: 0.9654\n",
      "Epoch:  6 Train accuracy: 0.99333334 Test accuracy: 0.9679\n",
      "Epoch:  7 Train accuracy: 0.98 Test accuracy: 0.9754\n",
      "Epoch:  8 Train accuracy: 0.98 Test accuracy: 0.9717\n",
      "Epoch:  9 Train accuracy: 0.98 Test accuracy: 0.9737\n",
      "Epoch:  10 Train accuracy: 1.0 Test accuracy: 0.9757\n",
      "Epoch:  11 Train accuracy: 0.98 Test accuracy: 0.9779\n",
      "Epoch:  12 Train accuracy: 0.99333334 Test accuracy: 0.9742\n",
      "Epoch:  13 Train accuracy: 0.9866667 Test accuracy: 0.9704\n",
      "Epoch:  14 Train accuracy: 0.99333334 Test accuracy: 0.9765\n",
      "Epoch:  15 Train accuracy: 0.99333334 Test accuracy: 0.9747\n",
      "Epoch:  16 Train accuracy: 0.99333334 Test accuracy: 0.9733\n",
      "Epoch:  17 Train accuracy: 0.99333334 Test accuracy: 0.9786\n",
      "Epoch:  18 Train accuracy: 1.0 Test accuracy: 0.9789\n",
      "Epoch:  19 Train accuracy: 0.97333336 Test accuracy: 0.9787\n",
      "Epoch:  20 Train accuracy: 0.99333334 Test accuracy: 0.9785\n",
      "Epoch:  21 Train accuracy: 0.9866667 Test accuracy: 0.974\n",
      "Epoch:  22 Train accuracy: 0.99333334 Test accuracy: 0.9735\n",
      "Epoch:  23 Train accuracy: 0.99333334 Test accuracy: 0.9801\n",
      "Epoch:  24 Train accuracy: 0.9866667 Test accuracy: 0.9782\n",
      "Epoch:  25 Train accuracy: 0.99333334 Test accuracy: 0.981\n",
      "Epoch:  26 Train accuracy: 1.0 Test accuracy: 0.9772\n",
      "Epoch:  27 Train accuracy: 0.99333334 Test accuracy: 0.9804\n",
      "Epoch:  28 Train accuracy: 0.9866667 Test accuracy: 0.9772\n",
      "Epoch:  29 Train accuracy: 1.0 Test accuracy: 0.9781\n",
      "Epoch:  30 Train accuracy: 1.0 Test accuracy: 0.9778\n",
      "Epoch:  31 Train accuracy: 1.0 Test accuracy: 0.9774\n",
      "Epoch:  32 Train accuracy: 1.0 Test accuracy: 0.9772\n",
      "Epoch:  33 Train accuracy: 0.98 Test accuracy: 0.9728\n",
      "Epoch:  34 Train accuracy: 1.0 Test accuracy: 0.9797\n",
      "Epoch:  35 Train accuracy: 0.99333334 Test accuracy: 0.978\n",
      "Epoch:  36 Train accuracy: 1.0 Test accuracy: 0.9776\n",
      "Epoch:  37 Train accuracy: 0.98 Test accuracy: 0.976\n",
      "Epoch:  38 Train accuracy: 0.9866667 Test accuracy: 0.9641\n",
      "Epoch:  39 Train accuracy: 0.99333334 Test accuracy: 0.9789\n",
      "Epoch:  40 Train accuracy: 0.99333334 Test accuracy: 0.9754\n",
      "Epoch:  41 Train accuracy: 1.0 Test accuracy: 0.979\n",
      "Epoch:  42 Train accuracy: 1.0 Test accuracy: 0.9779\n",
      "Epoch:  43 Train accuracy: 1.0 Test accuracy: 0.9752\n",
      "Epoch:  44 Train accuracy: 1.0 Test accuracy: 0.9783\n",
      "Epoch:  45 Train accuracy: 0.99333334 Test accuracy: 0.9785\n",
      "Epoch:  46 Train accuracy: 0.99333334 Test accuracy: 0.9782\n",
      "Epoch:  47 Train accuracy: 1.0 Test accuracy: 0.9796\n",
      "Epoch:  48 Train accuracy: 1.0 Test accuracy: 0.976\n",
      "Epoch:  49 Train accuracy: 0.98 Test accuracy: 0.9799\n",
      "Epoch:  50 Train accuracy: 0.98 Test accuracy: 0.9777\n",
      "Epoch:  51 Train accuracy: 0.9866667 Test accuracy: 0.9789\n",
      "Epoch:  52 Train accuracy: 1.0 Test accuracy: 0.9751\n",
      "Epoch:  53 Train accuracy: 0.9866667 Test accuracy: 0.9805\n",
      "Epoch:  54 Train accuracy: 1.0 Test accuracy: 0.9778\n",
      "Epoch:  55 Train accuracy: 0.9866667 Test accuracy: 0.9785\n",
      "Epoch:  56 Train accuracy: 0.99333334 Test accuracy: 0.9777\n",
      "Epoch:  57 Train accuracy: 0.99333334 Test accuracy: 0.9797\n",
      "Epoch:  58 Train accuracy: 0.99333334 Test accuracy: 0.9804\n",
      "Epoch:  59 Train accuracy: 1.0 Test accuracy: 0.9789\n",
      "Epoch:  60 Train accuracy: 1.0 Test accuracy: 0.9824\n",
      "Epoch:  61 Train accuracy: 0.98 Test accuracy: 0.978\n",
      "Epoch:  62 Train accuracy: 1.0 Test accuracy: 0.979\n",
      "Epoch:  63 Train accuracy: 0.99333334 Test accuracy: 0.9803\n",
      "Epoch:  64 Train accuracy: 1.0 Test accuracy: 0.977\n",
      "Epoch:  65 Train accuracy: 1.0 Test accuracy: 0.9777\n",
      "Epoch:  66 Train accuracy: 0.99333334 Test accuracy: 0.9808\n",
      "Epoch:  67 Train accuracy: 0.99333334 Test accuracy: 0.9791\n",
      "Epoch:  68 Train accuracy: 0.9866667 Test accuracy: 0.975\n",
      "Epoch:  69 Train accuracy: 0.9866667 Test accuracy: 0.9793\n",
      "Epoch:  70 Train accuracy: 0.99333334 Test accuracy: 0.974\n",
      "Epoch:  71 Train accuracy: 0.96666664 Test accuracy: 0.9765\n",
      "Epoch:  72 Train accuracy: 0.99333334 Test accuracy: 0.9783\n",
      "Epoch:  73 Train accuracy: 0.99333334 Test accuracy: 0.9801\n",
      "Epoch:  74 Train accuracy: 1.0 Test accuracy: 0.9741\n",
      "Epoch:  75 Train accuracy: 1.0 Test accuracy: 0.9815\n",
      "Epoch:  76 Train accuracy: 0.99333334 Test accuracy: 0.9777\n",
      "Epoch:  77 Train accuracy: 0.99333334 Test accuracy: 0.9778\n",
      "Epoch:  78 Train accuracy: 0.9866667 Test accuracy: 0.9805\n",
      "Epoch:  79 Train accuracy: 0.99333334 Test accuracy: 0.9798\n",
      "Epoch:  80 Train accuracy: 0.9866667 Test accuracy: 0.9796\n",
      "Epoch:  81 Train accuracy: 0.99333334 Test accuracy: 0.9811\n",
      "Epoch:  82 Train accuracy: 0.99333334 Test accuracy: 0.9761\n",
      "Epoch:  83 Train accuracy: 1.0 Test accuracy: 0.9765\n",
      "Epoch:  84 Train accuracy: 1.0 Test accuracy: 0.9781\n",
      "Epoch:  85 Train accuracy: 0.99333334 Test accuracy: 0.9748\n",
      "Epoch:  86 Train accuracy: 0.99333334 Test accuracy: 0.9796\n",
      "Epoch:  87 Train accuracy: 1.0 Test accuracy: 0.9747\n",
      "Epoch:  88 Train accuracy: 0.99333334 Test accuracy: 0.9815\n",
      "Epoch:  89 Train accuracy: 0.98 Test accuracy: 0.9777\n",
      "Epoch:  90 Train accuracy: 0.99333334 Test accuracy: 0.9781\n",
      "Epoch:  91 Train accuracy: 1.0 Test accuracy: 0.9796\n",
      "Epoch:  92 Train accuracy: 0.9866667 Test accuracy: 0.9786\n",
      "Epoch:  93 Train accuracy: 0.99333334 Test accuracy: 0.9794\n",
      "Epoch:  94 Train accuracy: 1.0 Test accuracy: 0.9789\n",
      "Epoch:  95 Train accuracy: 1.0 Test accuracy: 0.9786\n",
      "Epoch:  96 Train accuracy: 0.9866667 Test accuracy: 0.9587\n",
      "Epoch:  97 Train accuracy: 0.99333334 Test accuracy: 0.9799\n",
      "Epoch:  98 Train accuracy: 1.0 Test accuracy: 0.9785\n",
      "Epoch:  99 Train accuracy: 0.9866667 Test accuracy: 0.9789\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range( n_epochs):\n",
    "        for iteration in range( mnist.train.num_examples // batch_size + 1):\n",
    "            X_batch, y_batch = mnist.train.next_batch( batch_size)\n",
    "            X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict ={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict ={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval( feed_dict ={X: X_test, y: y_test})\n",
    "        print(\"Epoch: \", epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf35",
   "language": "python",
   "name": "tf35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
