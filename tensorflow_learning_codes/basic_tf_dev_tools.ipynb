{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oycy\\.conda\\envs\\tf35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up default Graph() of tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Managing Computation Graphs in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining computation graph\n",
    "x = tf.Variable(3, name='x')\n",
    "y = tf.Variable(4, name='y')\n",
    "f = x * x * y + y + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Direct Way to Run a Simple Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph will not run until executed by session\n",
    "sess = tf.Session()\n",
    "# variables need to be initiated\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "# once all variables are initiated, run f\n",
    "result = sess.run(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use context manager with Session to run a Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternatively, define a \"variable initializer\" node in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare an init node\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # init node initializes all Variables\n",
    "    init.run()\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Managing graphs when more than 1 is available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that all of the 3 nodes' `.graph` attribute point to the exact same computation graph (default graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# graph of f created above is the default graph\n",
    "print(f.graph is tf.get_default_graph())\n",
    "print(x.graph is tf.get_default_graph())\n",
    "print(y.graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicitly creating a new Graph() to store nodes\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "    # below line will raise exception since y is a node in\n",
    "    # another graph\n",
    "    #f2 = x2 * 3 * y\n",
    "    f2 = x2 * x2 * 3\n",
    "    # init will only initialize Variables **before** it\n",
    "    # before to have init latest of the pack\n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph needs to be defined explicitly here\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    init.run()\n",
    "    result = f2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the default graph was only teporarily set as graph\n",
    "graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lifecycle of Node Values\n",
    "\n",
    "Node values are only computed when running a evaluation through the graph, and are discarded once the computation is done. Only `Variable` values are maintained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph1 = tf.Graph()\n",
    "with graph1.as_default():\n",
    "    w = tf.constant(10)\n",
    "    x = w + 2\n",
    "    y = x + 4\n",
    "    z = x * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph1) as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Running Linear Regression with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick pull a sample dataset before running a TF Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "# obtain m and n, m is number of records and n is number of columns\n",
    "m, n = housing.data.shape\n",
    "# add 1s to the matrix for each row, which is for model bias / intercept\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(housing_data_plus_bias)\n",
    "scaled_housing_data_plus_bias = scaler.transform(housing_data_plus_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20640\n",
      "8\n",
      "[[ 0.          2.34476576  0.98214266  0.62855945 -0.15375759 -0.9744286\n",
      "  -0.04959654  1.05254828 -1.32783522]\n",
      " [ 0.          2.33223796 -0.60701891  0.32704136 -0.26333577  0.86143887\n",
      "  -0.09251223  1.04318455 -1.32284391]]\n"
     ]
    }
   ],
   "source": [
    "print(m)\n",
    "print(n)\n",
    "print(scaled_housing_data_plus_bias[:2, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TF Computation Graph using Normal Equation for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# load Variable as constant tensors\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "\n",
    "# Calculate theta using the normal equation\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.7185181e+01]\n",
      " [ 4.3633747e-01]\n",
      " [ 9.3952334e-03]\n",
      " [-1.0711310e-01]\n",
      " [ 6.4479220e-01]\n",
      " [-4.0338000e-06]\n",
      " [-3.7813708e-03]\n",
      " [-4.2348403e-01]\n",
      " [-4.3721911e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(theta_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TF Computation Graph using Gradient Descent for Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: Manual Computation of Gradient Descent (Batch GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT:**\n",
    "**Rescaling input data by column (feature) such that features all have same scale. This is VITAL for any GD solution!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the construction phase - build the `Graph()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# define hyper parameter\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# load training data\n",
    "# note that X and y are computed directly, indicating this is a\n",
    "# Batch GD\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "\n",
    "# start a random theta for GB. It should have (n + 1) elements\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "\n",
    "# calculate y_pred\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "\n",
    "# calculate error\n",
    "error = y_pred - y\n",
    "# calculate mean square error\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "# calculate gradients of the mse (loss function)\n",
    "gradients = 2 / m * tf.matmul(tf.transpose(X), error)\n",
    "\n",
    "# define GD update formula\n",
    "# note: tf.assign updates the Variable with new theta\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "# last but not least, create a init node\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the execution phase - run the `Graph()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: MSE = 8.853888511657715\n",
      "Epoch 100: MSE = 4.915576457977295\n",
      "Epoch 200: MSE = 4.845273494720459\n",
      "Epoch 300: MSE = 4.834809303283691\n",
      "Epoch 400: MSE = 4.828482151031494\n",
      "Epoch 500: MSE = 4.823597431182861\n",
      "Epoch 600: MSE = 4.819718360900879\n",
      "Epoch 700: MSE = 4.816625118255615\n",
      "Epoch 800: MSE = 4.81414270401001\n",
      "Epoch 900: MSE = 4.812143325805664\n",
      "[[-0.19455743]\n",
      " [ 0.90342915]\n",
      " [ 0.14384116]\n",
      " [-0.3839345 ]\n",
      " [ 0.39435384]\n",
      " [ 0.0036655 ]\n",
      " [-0.04302227]\n",
      " [-0.64767283]\n",
      " [-0.62590075]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            # note here when mse is evaluated, it does not call learning_op\n",
    "            # which actually updates the theta\n",
    "            print(\"Epoch {0}: MSE = {1}\".format(epoch, mse.eval()))\n",
    "        # note that training_op is run here which updates theta in ach epoch\n",
    "        sess.run(training_op)\n",
    "    # after all epochs are done, the theta has been assigned n_epoch times\n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Using TF's `autodiff` features to compute gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `tf.gradients()` to automatically calculate the gradient based on the computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# define hyper parameter\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# load training data\n",
    "# note that X and y are computed directly, indicating this is a\n",
    "# Batch GD\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "\n",
    "# start a random theta for GB. It should have (n + 1) elements\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "\n",
    "# calculate y_pred\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "\n",
    "# calculate error\n",
    "error = y_pred - y\n",
    "# calculate mean square error\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "# replace hand-written gradient computation with\n",
    "# tf.gradients() returns a list of gradients with regard\n",
    "# to each x\n",
    "gradients = tf.gradients(ys=[mse], xs=[theta])[0]\n",
    "\n",
    "# define GD update formula\n",
    "# note: tf.assign updates the Variable with new theta\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "# last but not least, create a init node\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: MSE = 7.3176445960998535\n",
      "Epoch 100: MSE = 5.145058631896973\n",
      "Epoch 200: MSE = 5.035160064697266\n",
      "Epoch 300: MSE = 4.9770097732543945\n",
      "Epoch 400: MSE = 4.934591770172119\n",
      "Epoch 500: MSE = 4.903024196624756\n",
      "Epoch 600: MSE = 4.879417896270752\n",
      "Epoch 700: MSE = 4.861688613891602\n",
      "Epoch 800: MSE = 4.848317623138428\n",
      "Epoch 900: MSE = 4.8381876945495605\n",
      "[[-0.8194535 ]\n",
      " [ 0.90355426]\n",
      " [ 0.17581181]\n",
      " [-0.3244198 ]\n",
      " [ 0.3188639 ]\n",
      " [ 0.01529535]\n",
      " [-0.04572967]\n",
      " [-0.414511  ]\n",
      " [-0.38986284]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            # note here when mse is evaluated, it does not call learning_op\n",
    "            # which actually updates the theta\n",
    "            print(\"Epoch {0}: MSE = {1}\".format(epoch, mse.eval()))\n",
    "        # note that training_op is run here which updates theta in ach epoch\n",
    "        sess.run(training_op)\n",
    "    # after all epochs are done, the theta has been assigned n_epoch times\n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3: Using TF's native optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# define hyper parameter\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# load training data\n",
    "# note that X and y are computed directly, indicating this is a\n",
    "# Batch GD\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "\n",
    "# start a random theta for GB. It should have (n + 1) elements\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "\n",
    "# calculate y_pred\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "\n",
    "# calculate error\n",
    "error = y_pred - y\n",
    "# calculate mean square error\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "# replace hand-written gradient computation with\n",
    "# tf.gradients() returns a list of gradients with regard\n",
    "# to each x\n",
    "gradients = tf.gradients(ys=[mse], xs=[theta])[0]\n",
    "\n",
    "# define GD update formula\n",
    "# note: tf.assign updates the Variable with new theta\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "# last but not least, create a init node\n",
    "init = tf.global_variables_initializer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf35",
   "language": "python",
   "name": "tf35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
